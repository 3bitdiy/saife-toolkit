[{"title":"internet intermediary","description":"<p>internet intermediaries can be different types of service providers that facilitate interactions on the internet. Some connect users to the internet, enable processing of data and host web-based services, including for user-generated comments. Others gather information, assist searches, facilitate the sale of goods and services, or enable other commercial transactions. Importantly, they may carry out several functions in parallel, including those that are not merely intermediary. Internet intermediaries often curate, recommend and rank content, mainly through algorithmic systems. One of the biggest questions related to internet intermediaries has been about their liability, whether they qualify as publishers and therefore can be held accountable for the content they host.</p>","sections":[]},{"title":"healthy online information spaces","description":"<p>describe a pluralistic, independent, inclusive, safe, and resilient information ecosystem for seeking, receiving, and imparting information in the digital realm that serves the public interest, promotes media freedom and reinforces democratic processes.</p>","sections":[]},{"title":"big tech","description":"<p>refers to the small number of powerful tech companies (social media platforms, search engines, and increasingly AI companies) that dominate the online information space, shaping how information is produced, distributed, accessed, and monetized. Due to the high concentration of power and their size, they exert significant control over the information environment, while their business models typically prioritize profit over human rights and the public interest.</p>","sections":[]},{"title":"generative ai","description":"<p>refers to AI models and tools trained on multi-format datasets with the potential to generate human-like outputs such as text, image, video, music or action based on the patterns identified in the data it was trained on (including both novel output and modified existing content).</p>","sections":[]},{"title":"algorithm","description":"<p>a set of instructions used to process information and deliver an output based on the instructions&rsquo; stipulations. Algorithms can be simple pieces of code but they can also be incredibly complex, &ldquo;encoding for thousands of variables across millions of data points.&rdquo; In the context of online platforms, some algorithms &ndash; because of their complexity, the amounts and types of user information fed into them, and the decision-making function they serve &ndash; have significant implications for users&rsquo; human rights, including freedom of expression and privacy. (Source: &ldquo;<a href=\"https://datasociety.net/wp-content/uploads/2018/04/Data_Society_Algorithmic_Accountability_Primer_FINAL-4.pdf\">Algorithmic Accountability: A Primer</a>,&rdquo; <span className=\"italic\">Data &amp; Society, </span>April 2018.)</p>","sections":[{"title":"algorithmic system","description":"<p>a system that uses algorithms, machine learning and/or related technologies to automate, optimize and/or personalize decision-making processes.</p>"},{"title":"algorithmic content curation, recommendation, and/or ranking","description":"<p>a system that uses algorithms, machine learning and other automated decision-making technologies to manage, shape, and govern the flow of content and information on a platform, typically in a way that is personalized to each individual user.</p>"}]},{"title":"content governance","description":"<p>There are a number of ways in which online content can be governed. Some common techniques include:</p>","sections":[{"title":"content moderation","description":"<p>the practice of screening user-generated content posted to internet sites, social media, and other online outlets, in order to determine the appropriateness of the content for a given site, locality, or jurisdiction. The process can result in the content being removed or restricted. In addition to human moderators, companies increasingly rely on AI-driven tools or algorithmic systems to moderate content on their platforms. (Source: Roberts S.T. (2017) <a href=\"https://doi.org/10.1007/978-3-319-32001-4_44-1\">Content Moderation</a>. In: Schintler L., McNeely C. (eds) <span className=\"italic\">Encyclopedia of Big Data</span>. Springer, Cham.). Moderation often includes <span className=\"font-bold\">filtering</span> as a type of automated mechanism applied by platforms based on their own terms of services or requested by governments and national laws usually to protect specific values, and stop access to &ldquo;problematic&rdquo; and/or illegal content. It also often includes <span className=\"font-bold\">hashing </span>as statistical and computer science technique to identify, match, predict, or classify content (e.g. comment, image or video) on the basis of its exact properties or general features. Techniques for matching content typically involve &ldquo;hashing,&rdquo; which is the process of turning content into a &ldquo;hash&rdquo;, a string of data to uniquely identify the underlying content (Source: Gorwa R, Binns R, Katzenbach C. &ldquo;<a href=\"https://doi.org/10.1177/2053951719897945\">Algorithmic Content Moderation: Technical and Political Challenges in the Automation of Platform Governance</a>.&rdquo;<span className=\"italic\"> Big Data &amp; Society</span>. January 2020.)</p>"},{"title":"content curation","description":"<p>practices to manage, shape, and govern the flow of content on a platform, typically in a way that is targeted at each individual user (personalization). Content curation, ranking, and recommendation can limit or restrict the visibility of and access to certain content, thereby restricting the diversity of ideas, access to information, and the fundamental right to receive and impart information.</p>"}]},{"title":"data inference","description":"<p>companies can create powerful profiles about individuals by using algorithmic technologies to make inferences, or predictions, about them based on preferences or attributes (e.g., race, gender, sexual orientation), and opinions (e.g., political stances). (Source: Wachter, S., &amp; Mittelstadt, B. <a href=\"https://doi.org/10.7916/cblr.v2019i2.3424\">A Right to Reasonable Inferences: Re-Thinking Data Protection Law in the Age of Big Data and AI</a>.<span className=\"italic\">Columbia Business Law Review</span>, <span className=\"italic\">2019</span>(2), 494&ndash;620).</p>","sections":[]},{"title":"disinformation and misinformation","description":"<p><span className=\"font-bold\">disinformation</span> is content that is intentionally false and that is disseminated for the purposes of influencing political behavior and electoral outcomes or to maliciously cause trouble or harm. Disinformation can be illegal in certain jurisdictions, and under certain circumstances. <span className=\"font-bold\">Misinformation</span> is generally regarded as content that is unintentionally false or misleading. Misinformation is not often regarded as unlawful, although it can also create or perpetuate harm.</p>","sections":[]},{"title":"human rights due diligence (HRDD)","description":"<p>is a formal process for identifying, preventing, mitigating, and accounting for human rights risk and impacts of a public or private sector policy or practice. Human rights due diligence includes implementing oversight and accountability mechanisms to identify and mitigate human rights harms occurring in the present and that could potentially occur in the future. A key component of human rights due diligence is meaningful engagement with stakeholders, particularly civil society and rights holders such as employees, community members, human rights defenders, supply chain workers, and consumers. (Source: <a href=\"http://www.ohchr.org/documents/%20publications/GuidingprinciplesBusinesshr_en.pdf\">Guiding Principles on Business and Human Rights: Implementing the United Nations &ldquo;Respect, Protect and Remedy&rdquo; Framework</a><a href=\"http://www.ohchr.org/documents/%20publications/GuidingprinciplesBusinesshr_en.pdf\">.</a> United Nations Office of the High Commissioner on Human Rights, 2011.) </p>","sections":[]},{"title":"human rights impact assessment (HRIA)","description":"<p>a structured approach to due diligence to evaluate how operations, policies, or regulations could negatively impact human rights and to design clear processes for mitigating those risks. (Further information: <a href=\"https://business-humanrights.org/en/un-guiding-principles/implementation-tools-examples/implementation-by-companies/type-of-step-taken/human-rights-impact-assessments\">Business &amp; Human Rights Resource Centre</a> and <a href=\"https://www.humanrights.dk/publications/human-rights-impact-assessment-digital-activities\">Practical guidance for businesses, and other actors in the digital ecosystem, on how to conduct human rights impact assessment of digital activities</a>.)</p>","sections":[]},{"title":"profiling","description":"<p>refers to a process of using algorithmic systems to predict or infer attributes about individuals based on data that were not disclosed, and to sort people into categories or classifications based on those inferences.</p>","sections":[]},{"title":"surveillance capitalism","description":"<p>is a revenue model based on the commodification of peoples&rsquo; data for profit. The model is based on the mass collection and processing of personal data in order to target users more precisely with commercial and other types of content to drive engagement and reach. First coined by Harvard scholar Shoshana Zuboff, the term is now used widely to describe what many experts and human rights advocates say is an inherently anti-democratic business model that is driving the proliferation of much of the harmful content online today.</p>","sections":[]},{"title":"targeted advertising","description":"<p>targeted advertising, also known as &ldquo;behavioral advertising&rdquo;, &ldquo;interest-based advertising&rdquo;, &ldquo;personalized advertising&rdquo;, or &ldquo;programmatic advertising&rdquo;, refers to the practice of delivering tailored ads to individuals based on their browsing history, location information, social media profiles and activities, as well as demographic characteristics and other features (and so-called lookalike audiences). Targeted advertising relies on mass data collection practices, which can involve tracking users&rsquo; activities across the internet using cookies, widgets, and other tracking tools, to create detailed user profiles.</p>","sections":[]}]