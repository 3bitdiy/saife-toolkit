[{"image":"data/resources/1.jpg","nr":"1","title":"Lightning Talks on the impact of AI on freedom of expression","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, April to June 2020","description":"A series of “Lightning Talk” presentations with AI experts to promote a clearer understanding of the effects on free speech and media pluralism stemming from the use of AI.","href":"https://www.osce.org/representative-on-freedom-of-media/451090","tags":["AI and human rights","AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/2.jpg","nr":"2","title":"Lightning Talk on the impact of AI on freedom of expression: How Artificial Intelligence (AI) can impact media pluralism","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, May 2020","description":"Krisztina Rozgonyi, assistant professor at the University of Vienna and legal and regulatory expert on media governance, explains the main impact that the use of AI and automation have on access to information and media diversity online.","href":"https://www.osce.org/representative-on-freedom-of-media/452452","tags":["AI in content curation: Media pluralism"]},{"image":"data/resources/3.jpg","nr":"3","title":"Lighting Talk on the impact of AI on freedom of expression: The growing impact of AI on free speech during the COVID-19 pandemic","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, May 2020","description":"Eliška Pírková, Europe Policy Analyst at Access Now explains how the impact of AI on free speech became even more visible during the COVID-19 pandemic.","href":"https://www.osce.org/representative-on-freedom-of-media/453261","tags":["AI in content curation: Media pluralism"]},{"image":"data/resources/4.jpg","nr":"4","title":"Lighting Talk on the impact of AI on freedom of expression: How surveillance and data capitalism - especially when using AI - can impact freedom of expression","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, June 2020","description":"Human rights lawyer Carly Kind, director of the Ada Lovelace Institute, explains how the use of AI and data collection, surveillance capitalism and state surveillance are closely intertwined, and how it can impact access to information and freedom of speech.","href":"https://www.osce.org/representative-on-freedom-of-media/455977","tags":["AI in content curation: Surveillance capitalism","AI in content curation: Media pluralism"]},{"image":"data/resources/5.jpg","nr":"5","title":"Lighting Talk on the impact of AI on freedom of expression: How automated bots and the use of algorithms and AI can influence public discourse and pluralism online","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, June 2020","description":"Ingrid Brodnig, digital expert and scholar, explains how automated bots and the use of algorithms and AI can influence public discourse and pluralism online, while she emphasizes the need for more transparency.","href":"https://www.osce.org/representative-on-freedom-of-media/454420","tags":["AI in content curation: Media pluralism"]},{"image":"data/resources/6.jpg","nr":"6","title":"Lighting Talk on the impact of AI on freedom of expression: Challenges to freedom of expression in the use of AI to identify and remove hate speech online","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, April 2020","description":"Lorena Jaume-Palasí, founder of The Ethical Tech Society, and co-founder of AlgorithmWatch and the Internet Governance Forum Academy, introduces a major challenge to freedom of expression in the use of AI to identify and remove hate speech online.","href":"https://www.osce.org/representative-on-freedom-of-media/450847","tags":["AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/7.jpg","nr":"7","title":"Lighting Talk on the Impact of AI on freedom of expression: Main challenges to freedom of expression of using artificial intelligence (AI) for removing terrorist and extremist content online","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, April 2020","description":"Djordje Krivokapić, lawyer, co-founder of the SHARE Foundation and Professor at the University of Belgrade, introduces the main challenges to freedom of expression when using artificial intelligence (AI) for removing terrorist and extremist content online.","href":"https://www.osce.org/representative-on-freedom-of-media/449917","tags":["AI in content moderation: Illegal content and security threats"]},{"image":"data/resources/8.jpg","nr":"8","title":"Interview series on AI and COVID-19 Disinformation","category":"Read","subtitle":"SAIFE Spotlight Initiative, Kyle Matthews, February-March 2021","description":"This initiative in co-operation with Kyle Matthews, Executive Director of the Montreal Institute for Genocide and Human Rights Studies (MIGS) at Concordia University, explores the impact of AI in enabling and confronting COVID-19 related disinformation, as well as the intersection of AI in relation to digital threats that are taking advantage of the pandemic “infocalypse”. A series of interviews with renowned experts from different backgrounds explores policies on how AI can be harnessed and regulated to better counter online disinformation and guarantee freedom of expression, including in times of crises.","href":"https://www.osce.org/fom/ai-free-speech/spotlight-initiatives","tags":["AI and human rights","AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/9.jpg","nr":"9","title":"Non-paper on the impact of artificial intelligence on freedom of expression","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, March 2020","description":"This paper reviews the impact of AI and algorithms on human rights, focusing on how these technologies can be deployed in ways that censor the news and other information and stifle media freedom.","href":"https://www.osce.org/representative-on-freedom-of-media/447829","tags":["AI and human rights","AI governance"]},{"image":"data/resources/10.jpg","nr":"10","title":"Policy paper on freedom of the media and artificial intelligence","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, November 2020","description":"While AI can improve communications, it can also be deployed in ways that can threaten human rights. In this paper, Julia Haas of the Office of the OSCE Representative on Freedom of the Media presents a summary of how AI can negatively impact freedom of expression and media freedom.","href":"https://www.osce.org/representative-on-freedom-of-media/472488","tags":["AI and human rights","AI in content curation: Media pluralism","AI governance"]},{"image":"data/resources/11.jpg","nr":"11","title":"Artificial Intelligence and Disinformation as a Multilateral Policy Challenge","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, November 2021","description":"A paper discussing the century-old, international problem of how to counteract the dissemination of false reports and information. Prepared by Deniz Wagner, Adviser to the OSCE Representative on Freedom of the Media.","href":"https://rm.coe.int/msi-dig-2020-05-draft-recommendation-on-the-impact-of-digital-technolo/1680a43c8e","tags":["AI and human rights","AI governance"]},{"image":"data/resources/12.jpg","nr":"12","title":"Fourth expert meeting: Deepfake news – Artificial intelligence and disinformation as a multilateral policy challenge","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, December 2021","description":"An expert roundtable exploring the role that AI can play in both enabling and combating the spread of disinformation. Experts also discuss the broader socio-technical context of online disinformation, and what safeguards are needed to protect freedom of expression and media pluralism.","href":"https://www.osce.org/representative-on-freedom-of-media/506347","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/13.jpg","nr":"13","title":"Compilation report of the public online consultation on AI and free speech","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, 2021","description":"In this report, the OSCE Representative on Freedom of the Media presents outcomes of an online public consultation conducted in 2020 to collect views, input, and feedback on the topic of AI and freedom of expression, and preliminary recommendations presented in the SAIFE Strategy Paper. This report outlines responses to survey questions and identifies emerging trends from responses received.","href":"https://www.osce.org/representative-on-freedom-of-media/485651","tags":["AI and human rights","AI governance"]},{"image":"data/resources/14.jpg","nr":"14","title":"Video Launch: the SAIFE Policy Manual","category":"Watch","subtitle":"Office of the OSCE Representative on Freedom of the Media, January 2022","description":"A livestream event featuring the launch of the SAIFE Policy Manual, the culmination of two years of research and several expert workshops, bringing together more than 120 experts from various backgrounds and across the OSCE region. The SAIFE Policy Manual provides human rights-centric recommendations to safeguard freedom of expression in the use of AI in content moderation and curation.","href":"https://www.osce.org/representative-on-freedom-of-media/510347","tags":["AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism","AI governance"]},{"image":"data/resources/15.jpg","nr":"15","title":"DECISION No. 3/18 SAFETY OF JOURNALISTS, 7 December 2018","category":"Read","description":"This consensus document agreed by all 57 OSCE participating States focuses on numerous inter-related aspects of the safety of journalists and introduces new political commitments. It calls to fully implement all OSCE commitments and their international obligations related to freedom of expression and media freedom, including to respect international obligations protecting the safety of journalists.","href":"https://www.osce.org/files/mcdec0003%20safety%20of%20journalists%20en.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/16.jpg","nr":"16","title":"OSCE Representative on Freedom of the Media's regular reports to the Permanent Council","category":"Read","subtitle":"OSCE Representative on Freedom of the Media","description":"A collection of reports on media freedom developments in the OSCE region, presented by the OSCE Representative on Freedom of the Media to the OSCE Permanent Council.","href":"https://www.osce.org/fom/66084","tags":["AI and human rights","AI governance"]},{"image":"data/resources/17.jpg","nr":"17","title":"Safety of Female Journalists Online","category":"Read","subtitle":"OSCE Representative on Freedom of the Media","description":"A repository of materials related to the Office of the OSCE Representative on Freedom of the Media’s project on the Safety of Female Journalists Online (SOFJO).","href":"https://www.osce.org/fom/safety-female-journalists-online","tags":["AI and human rights","AI governance"]},{"image":"data/resources/18.jpg","nr":"18","title":"Expert roundtables on Disinformation","category":"Watch","subtitle":"Organized by the OSCE Representative on Freedom of the Media","description":"A series of expert roundtables on disinformation and media freedom, organized by the Office of the OSCE Representative on Freedom of the Media.","href":"https://www.osce.org/representative-on-freedom-of-media/488890","tags":["AI and human rights"]},{"image":"data/resources/19.jpg","nr":"19","title":"Joint Declarations","category":"Read","subtitle":"International free speech mandate holders","description":"A collection of the Joint Declarations launched by the OSCE Representative on Freedom of the Media, the UN Special Rapporteur on Freedom of Opinion and Expression, the Organization of American States (OAS) Special Rapporteur on Freedom of Expression, and the African Commission on Human and Peoples’ Rights (ACHPR) Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/fom/66176","tags":["AI and human rights","AI governance"]},{"image":"data/resources/20.jpg","nr":"20","title":"Joint Declaration on Media Freedom and Democracy","category":"Read","subtitle":"May 2023","description":"Joint Declaration on the role of media freedom in creating and sustaining democratic societies by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/files/f/documents/1/e/379351.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/21.jpg","nr":"21","title":"Joint Declaration on Media Independence and Diversity in the Digital Age","category":"Read","subtitle":"May 2018","description":"Joint Declaration on the importance of an independent, pluralistic media in the digital age by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/files/f/documents/1/e/379351.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/22.jpg","nr":"22","title":"Joint Declaration on Freedom of Expression and Elections in the Digital Age","category":"Read","subtitle":"April 2020","description":"Joint Declaration affirming commitments to freedom of expression during times of elections in the digital age by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, and the OAS Special Rapporteur on Freedom of Expression.","href":"https://www.osce.org/representative-on-freedom-of-media/451150","tags":["AI and human rights","AI governance"]},{"image":"data/resources/23.jpg","nr":"23","title":"Twentieth Anniversary Joint Declaration: Challenges to Freedom of Expression in the Next Decade.","category":"Read","subtitle":"May 2016","description":"Joint Declaration on the importance of protecting online freedom of expression in the digital age by UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/files/f/documents/9/c/425282.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/24.jpg","nr":"24","title":"Joint Declaration on Freedom of Expression and Countering Violent Extremism","category":"Read","subtitle":"May 2016","description":"Joint Declaration on countering violent extremist content in a way compliant with freedom of expression by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/fom/237966","tags":["AI and human rights","AI governance"]},{"image":"data/resources/25.jpg","nr":"25","title":"Joint Declaration on Politicians and Public Officials and Freedom of Expression.","category":"Read","subtitle":"October 2021","description":"Joint Declaration focusing on political speech and speech by politicians and public officials by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression, and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/representative-on-freedom-of-media/501697","tags":["AI and human rights","AI governance"]},{"image":"data/resources/26.jpg","nr":"26","title":"Joint Declaration on freedom of expression and “fake news”, disinformation and propaganda.","category":"Read","subtitle":"March 2017","description":"Joint Declaration providing recommendations on combatting disinformation in accordance with international human rights standards by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information","href":"https://www.osce.org/fom/302796","tags":["AI and human rights","AI governance","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/27.jpg","nr":"27","title":"Joint Declaration on Freedom of Expression and Gender Justice.","category":"Read","subtitle":"May 2022","description":"Joint Declaration on transformative changes for gender justice in freedom of expression, including in the digital context, by the UN Special Rapporteur on Freedom of Opinion and Expression, the OSCE Representative on Freedom of the Media, the OAS Special Rapporteur on Freedom of Expression and the ACHPR Special Rapporteur on Freedom of Expression and Access to Information.","href":"https://www.osce.org/representative-on-freedom-of-media/517266","tags":["AI and human rights","AI in content curation: Media pluralism","AI in content curation: Media pluralism"]},{"image":"data/resources/28.jpg","nr":"28","title":"Event on Gender Justice: Advancing Pluralism and Free Speech For All","category":"Watch","subtitle":"Organized by the OSCE Representative on Freedom of the Media, July 2022\n","description":"The event discusses transformative change to remove systemic inequalities, barriers and discrimination in view of achieving gender justice and an enabling environment for pluralism and freedom of expression for all, and launches policy papers focusing on online rape threats, digital security hazards and targeted disinformation from the perspective of the (mis-)use of technology and automated systems to disempower women’s exercise of freedom of expression.","href":"https://www.osce.org/representative-on-freedom-of-media/521872","tags":["AI and human rights","AI in content curation: Media pluralism","AI in content curation: Media pluralism"]},{"image":"data/resources/29.jpg","nr":"29","title":"Communiqués by the OSCE Representative on Freedom of the Media","category":"Read","subtitle":"Organized by the OSCE Representative on Freedom of the Media, July 2022","description":"A collection of communiqués on fundamental media freedom issues.","href":"https://www.osce.org/representative-on-freedom-of-media/119497","tags":["AI and human rights","AI governance"]},{"image":"data/resources/29a.jpg","nr":"29a","title":"Countering the use of the Internet for terrorist purposes","category":"Read","subtitle":"OSCE Representative on Freedom of the Media","description":"A collection of materials pertaining to the OSCE Representative on Freedom of the Media’s initiatives to promoting human rights compliant and gender-mainstreamed best practices aimed at effectively preventing and countering violent extremism and terrorism online.","href":"https://www.osce.org/secretariat/107810","tags":["AI and human rights","AI governance","AI in content moderation: Illegal content and security threats"]},{"image":"data/resources/30.jpg","nr":"30","title":"Press release: Greater efforts needed to ensure digital technologies empower human rights, OSCE leaders say","category":"Read","subtitle":"OSCE Office for Democratic Institutions and Human Rights, July 2021","description":"Understanding the implications of digital technology is key to the protection and promotion of human rights in the 21st century, OSCE leaders said as a two-day online conference focused on the opportunities and challenges of the digital age for human rights and democracy.","href":"https://www.osce.org/chairmanship/492730","tags":["AI and human rights"]},{"image":"data/resources/31.jpg","nr":"31","title":"Press release: The power of digital technologies must be harnessed to counter hatred based on religion or belief, ODIHR says","category":"Read","subtitle":"OSCE Office for Democratic Institutions and Human Rights, August 2020","description":"On the eve of the International Day Commemorating the Victims of Acts of Violence Based on Religion or Belief, the OSCE Office for Democratic Institutions and Human Rights (ODIHR) calls for better use to be made of the advantages that digital technologies can offer, as well as a greater emphasis on countering hatred online","href":"https://www.osce.org/chairmanship/492730","tags":["AI and human rights"]},{"image":"data/resources/32.jpg","nr":"32","title":"Can there be security without media freedom? - Report on the occasion of the 25th Anniversary of the Mandate of the OSCE Representative on Freedom of the Media","category":"Read","subtitle":"OSCE Representative on Freedom of the Media, November 2022","description":"On the occasion of the 25th anniversary of the mandate of the OSCE Representative on Freedom of the Media, the RFoM established an Advisory Group of Eminent Experts on Freedom of the Media to take a birds-eye view on the media freedom situation and its linkage to security. This report highlights the expert discussions on current and emerging trends and challenges for media freedom – including in the digital realm, and the potential role of the RFoM in addressing these issues.","href":"https://www.osce.org/files/f/documents/8/d/530239.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/33.jpg","nr":"33","title":"There is no security without media freedom: 25th anniversary of the RFoM mandate","category":"Watch","subtitle":"Organized by the OSCE Representative on Freedom of the Media, November 2022\n","description":"This event commemorates the 25th anniversary of the mandate of the OSCE Representative on Freedom of the Media and presents the report “Can there be security without media freedom?” based on the discussions that the members of the Advisory Group Eminent Experts on Freedom of the Media (AGEEFOM).","href":"https://www.youtube.com/watch?v=vk6eoCt7HjI","tags":["AI and human rights","AI governance"]},{"image":"data/resources/34.jpg","nr":"34","title":"Communiqué by the OSCE Representative on Freedom of the Media on the Use of Digital Surveillance Technology on Journalists","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, September 2023","description":"In this communiqué on the use of digital surveillance technology on journalists, the RFoM underscores the significant negative impact such technology can have on media freedom and urges against their use on journalists.","href":"https://www.osce.org/representative-on-freedom-of-media/551605","tags":["AI and human rights","AI in content curation: Surveillance capitalism","AI governance"]},{"image":"data/resources/35.jpg","nr":"35","title":"Strategy paper to Put a Spotlight on Artificial Intelligence and Freedom of Expression","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, July 2020","description":"This paper addresses the impact of artificial intelligence on freedom of expression, focusing on key challenges of deploying AI to curate and moderate online content, particularly for content related to national security and hate speech. It identifies a number of overarching problems that AI poses to freedom of expression and to human rights more broadly, which stem from a lack of transparency in the design and deployment of AI, a lack of accountability and independent oversight over these AI systems, and a lack of effective remedies for freedom of expression violations linked to or caused by AI.","href":"https://www.osce.org/representative-on-freedom-of-media/456319","tags":["AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism","AI governance"]},{"image":"data/resources/36.jpg","nr":"36","title":"The Rise of Artificial Intelligence & How it will Reshape the Future of Free Speech","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, July 2020","description":"Experts from civil society, academia, and the tech industry discuss the impact of artificial intelligence, algorithmic systems, and machine-learning technologies in shaping and arbitrating online information, the potential risks this poses to freedom of expression, and ways to safeguard free speech when deploying automation and AI.","href":"https://www.osce.org/representative-on-freedom-of-media/455605","tags":["AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism","AI and human rights"]},{"image":"data/resources/37.jpg","nr":"37","title":"SAIFE Policy Manual","category":"Read","subtitle":"Office of the OSCE Representative on Freedom of the Media, January 2022","description":"The SAIFE Policy Manual is the culmination of two years of research and several expert workshops, bringing together more than 120 experts from various backgrounds and across the OSCE region and provides human rights-centric recommendations to safeguard freedom of expression in the use of AI in content moderation and curation.","href":"https://www.osce.org/files/f/documents/8/f/510332_0.pdf","tags":["AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism","AI governance"]},{"image":"data/resources/38.jpg","nr":"38","title":"SAIFE expert working group on content moderation and security","category":"Read","subtitle":"Agenda, Concept Note, Miro Boards – April 2021","description":"This SAIFE working group explored the free speech implication ofAI-based tools deployed in content moderation to detect and evaluate illegal content online, including security threats, such as extremist and terrorist content. It's outcome report fed into the SAIFE Policy Manual.","tags":["AI and human rights","AI in content moderation: Illegal content and security threats"]},{"image":"data/resources/39.jpg","nr":"39","title":"SAIFE expert working group on content moderation and hate speech","category":"Read","subtitle":"Agenda, Concept Note, Miro Boards – April 2021","description":"This SAIFE working group explored the free speech implications of AI-based tools used for detecting and evaluating potentially harmful but legal content, with a specific focus on online hate speech and algorithmic discriminatory bias. It's outcome report fed into the SAIFE Policy Manual.","tags":["AI and human rights","AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/40.jpg","nr":"40","title":"SAIFE expert working group on content curation and media pluralism","category":"Read","subtitle":"Agenda, Concept Note, Miro Boards – June 2021","description":"This SAIFE working group explored the free speech implications of AI-based tools designed for curating and personalising online content, with a focus on content recommender systems and their impact on media pluralism. It's outcome report fed into the SAIFE Policy Manual.","tags":["AI and human rights","AI in content curation: Media pluralism"]},{"image":"data/resources/41.jpg","nr":"41","title":"SAIFE expert working group on content curation and surveillance","category":"Read","subtitle":"Agenda, Concept Note, Miro Boards – July 2021","description":"This SAIFE working group explored the free speech implications of AI-based tools used in surveillance-based advertisement and their link to curating content through profiling of individuals and \r\npredicting future behaviours. It's outcome report fed into the SAIFE Policy Manual.","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/42.jpg","nr":"42","title":"SAIFE expert workshop on content governance in times of crisis","category":"Read","subtitle":"Agenda, Concept Note, Miro Boards – October 2022","description":"This SAIFE workshop explored the specific crisis-context of platform and content governance, building on the SAIFE Policy Manual and exploring implications and experiences in the context of the COVID-19 pandemic, conflicts, and the climate crisis.","tags":["AI and human rights","AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech","AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/43.jpg","nr":"43","title":"Decoding Hate podcast","category":"Listen","subtitle":"SAIFE Spotlight Initiative, Katie Pentney, February 2021\n","description":"A six-episode series that explores the connection between freedom of expression, artificial intelligence, and hate speech online. Human rights lawyer Katie Pentney discusses with leading experts what freedom of expression means in the digital age, the challenges of combating online hate speech, and the complexities of content moderation. \n\nFeaturing discussions with: Nani Jansen Reventlow; Deniz Wagner; Tarlach McGonagle; Jillian York; Thiago Dias Oliva; Sahana Udupa; Molly Land; and Rikke Frank Jørgensen\n","href":"https://www.decodinghatepod.com","tags":["AI and human rights","AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/44.jpg","nr":"44","title":"Better Human podcast","category":"Listen","subtitle":"SAIFE Spotlight Initiative, Susie Alegre, January-March 2021\n","description":"Human rights lawyer Susie Alegre joins the Better Human—a popular podcast hosted by UK barrister Adam Wagner—to lead a series of episodes that delve into an overlooked aspect of freedom of expression in the context of AI: freedom of opinion and freedom of information. Alegre invites experts from around the world to discuss the right to receive information and the ways in which AI affects what information we see and share. \r\n\r\nFeaturing interviews with: Meetali Jain, Legal Director of Avaaz; Dr. Emma L. Briant, Maven of Persuasion; Professor Lorna Woods, University of Essex; Dr. Elif Mendos Kuskonmaz, University of Portsmouth; Brendan de Caires, Director of PEN Canada; and Professor Evelyn Aswad, University of Oklahoma.\r\n","href":"https://podcasters.spotify.com/pod/show/better-human","tags":["AI and human rights"]},{"image":"data/resources/45.jpg","nr":"45","title":"Policy paper on AI and freedom of expression in political competition and elections","category":"Read","subtitle":"SAIFE Spotlight Initiative, Election-Watch.EU, Vienna Data Science Group, April 2021","description":"The policy paper developped by the Election-Watch.EU and the data4good Initiative of the Vienna Data Science Group (VDSG) addresses the impact of AI on freedom of expression in political campaigns and elections. Authors recommend human rights-based AI policies and regulatory measures that enable freedom of expression and the right to political participation.","href":"https://www.osce.org/files/f/documents/a/3/483638.pdf","tags":["AI and human rights","AI in content curation: Media pluralism"]},{"image":"data/resources/46.jpg","nr":"46","title":"Guidelines for API Access to Social Media.","category":"Read","subtitle":"SAIFE Spotlight Initiative, Thomas Treml, Rania Wazir and Armin Rabitsch, January 2021","description":"This report by Thomas Treml, Rania Wazir, and Armin Rabitsch describes the procedures for obtaining access to the application programming interface (APIs) for Twitter and Facebook, to provide useful guidance for researchers and civil society seeking data when conducting research on social media trends.","href":"https://www.osce.org/files/f/documents/d/b/483644.pdf","tags":["AI and human rights"]},{"image":"data/resources/47.jpg","nr":"47","title":"AI Explanations","category":"Read","subtitle":"SAIFE Spotlight Initiative, Caroline Sinders and Bojana Kostic, February 2021","description":"A feminist collective of digital rights researchers, design thinkers, artists, journalists and social media specialists explore questions how artificial intelligence shapes our realities, human rights, and access to justice and equality.","href":"https://www.ai-explanations.com/about","tags":["AI and human rights","AI in content curation: Media pluralism"]},{"image":"data/resources/48.jpg","nr":"48","title":"Algorithmic Accountability for the Public Sector","category":"Read","subtitle":"Ada Lovelace Institute, AI Now Institute, and Open Government Partnership, 2021","description":"A report mapping the challenges and successes of implementing algorithmic accountability policies, including practical case studies.","href":"https://www.opengovpartnership.org/wp-content/uploads/2021/08/executive-summary-algorithmic-accountability.pdf","tags":["AI and human rights"]},{"image":"data/resources/49.jpg","nr":"49","title":"Getting the Future Right – Artificial Intelligence and Fundamental Rights in the EU","category":"Read","subtitle":"EU Agency for Fundamental Rights, 2020","description":"A report by the EU Agency for Fundamental Rights (FRA) highlighting the urgent need to imbed human rights safeguards into how artificial intelligence is developed and deployed. Findings based on 91 interviews with public administration officials and staff members of private companies in select EU-member states. They were asked about their use of AI, their awareness of the fundamental rights issues involved, and best practices for assessing and mitigating risks linked to the use of AI.","href":"https://fra.europa.eu/en/publication/2020/artificial-intelligence-and-fundamental-rights","tags":["AI and human rights"]},{"image":"data/resources/50.jpg","nr":"50","title":"Artificial Intelligence and Human Rights","category":"Read","subtitle":"Eileen Donahoe and Megan MacDuffee Metzger. Journal of Democracy, vol. 30 no. 2, 2019, p. 115-126","description":"The rapid adoption of AI systems by both governments and the private sector have sparked concerns about potential negative implications for human dignity, democratic accountability, and the bedrock principles of free societies. Authors advocate for a global AI governance framework grounded in international human rights.","href":"https://www.journalofdemocracy.org/articles/artificial-intelligence-and-human-rights","tags":["AI and human rights"]},{"image":"data/resources/51.jpg","nr":"51","title":"Surveillance Giants: How the Business Model of Google and Facebook Threatens Human Rights","category":"Read","subtitle":"Amnesty International, 2019","description":"A report illuminating how the surveillance-based business model of Facebook and Google is inherently incompatible with the right to privacy and poses a systemic threat to a range of other rights, including freedom of opinion and expression, freedom of thought, and the right to equality and non-discrimination.","href":"https://amnestyusa.org/wp-content/%20uploads/2019/11/Surveillance-Giants-Embargo-21-%20Nov-0001-GMT-FINAL-report.pdf","tags":["AI in content curation: Surveillance capitalism"]},{"image":"data/resources/52.jpg","nr":"52","title":"It's Not Just the Content, It's the Business Model: Democracy’s Online Speech Challenge\n","category":"Read","subtitle":"Nathalie Maréchal and Ellery Roberts Biddle, Ranking Digital Rights, 2020","description":"A report articulating the connection between surveillance-based business models and the health of U.S. democracy. Drawing from Ranking Digital Rights’ extensive research on corporate policies and digital rights, the report examines how content curation and content moderation algorithms are used to propagate and prohibit different forms of online speech, and how this can cause or catalyze social harm, particularly in the context of the 2020 U.S. election.","href":"https://www.newamerica.org/oti/reports/its-not-just-content-its-business-model","tags":["AI in content curation: Surveillance capitalism"]},{"image":"data/resources/53.jpg","nr":"53","title":"Getting to the Source of Infodemics: It’s the Business Model","category":"Read","subtitle":"Nathalie Maréchal, Rebecca MacKinnon, and Jessica Dheere, Ranking Digital Rights, 2020","description":"A report addressing the root cause of the proliferation of harmful content online: the surveillance-based business model. Authors make the case for policy solutions that address the systemic causes of today’s “infodemic”—with measures that include corporate governance reform and strong data protection rules—rather than solutions that require intermediaries to police and remove harmful materials, which can result in undue restrictions to online speech and access to information online.","href":"https://www.newamerica.org/oti/reports/getting-to-the-source-of-infodemics-its-the-business-model","tags":["AI in content curation: Surveillance capitalism"]},{"image":"data/resources/54.jpg","nr":"54","title":"Human Rights in the Age of Artificial Intelligence","category":"Read","subtitle":"Access Now, 2018","description":"A report advocating for the application of international human rights law as the framework for developing global AI policy. It includes policy recommendations that push for strong data protection rules to protect privacy rights in the data sets used to develop and feed artificial intelligence systems; special safeguards for government uses of artificial intelligence; safeguards for private sector uses of artificial intelligence systems; and investment in more research to continue to examine the future of artificial intelligence and its potential interferences with human rights.","href":"https://www.accessnow.org/cms/assets/uploads/2018/11/AI-and-Human-Rights.pdf","tags":["AI and human rights"]},{"image":"data/resources/55.jpg","nr":"55","title":"Rising Through the Ranks: How Algorithms Rank and Curate Content in Search Results and on News Feeds","category":"Read","subtitle":"Spandana Singh. New America’s Open Technology Institute, 2019","description":"A report exploring how internet platforms are using automated tools to shape the content we see and access, analyzing how ranking, prioritization, and recommendation systems work and deliver targeted content to users.","href":"https://www.newamerica.org/oti/reports/rising-through-ranks/","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/56.jpg","nr":"56","title":"A Right to Reasonable Inferences: Re-Thinking Data Protection Law in the Age of Big Data and AI","category":"Read","subtitle":"Sandra Wachter and Brent Mittelstadt, Columbia Business Law Review, 2019","description":"A study of how big data analytics and artificial intelligence are used to draw often unverifiable inferences and predictions about the behaviors, preferences, and private lives of individuals. These inferences draw on deeply privacy-invasive datasets that can result discriminatory and biased algorithms.","href":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3248829","tags":["AI in content curation: Media pluralism","AI in content curation: Media pluralism"]},{"image":"data/resources/57.jpg","nr":"57","title":"How Recommendation Algorithms Run the World","category":"Read","subtitle":"Zeynep Tufekci, Wired, 2019","description":"Sociologist Zeynep Tufekci explores how recommendation algorithms influence what people buy, read, and watch online, based on highly opaque digital profiles of users assembled by private platforms using troves of personal data.","href":"https://www.wired.com/story/how-recommendation-algorithms-run-the-world","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/58.jpg","nr":"58","title":"Do You See What I See? Capabilities and Limits of Automated Multimedia Content Analysis","category":"Read","subtitle":"Dhanaraj Thakur and Emma Llansó. Center for Democracy & Technology, 2021","description":"This paper by CDT explains the capabilities and limitation sof tools for analyzing online content, in particular multimedia content. It highlights the potential risks of using these tools at scale without accounting for their limitations.","href":"https://cdt.org/insights/do-you-see-what-i-see-capabilities-and-limits-of-automated-multimedia-content-analysis","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/59.jpg","nr":"59","title":"Algorithmic content moderation: Technical and political challenges in the automation of platform governance","category":"Read","subtitle":"Robert Gorwa, Reuben Binns, and Christian Katzenbach, Big Data & Society, 2020","description":"A technical primer of how algorithmic moderation works. This report examines some of the existing automated tools used by major platforms to handle copyright infringement, terrorist content, and toxic speech, and identifies key issues and challenges of these applications, particularly as reliance on them grows.","href":"https://www.researchgate.net/publication/339576818_Algorithmic_content_moderation_Technical_and_political_challenges_in_the_automation_of_platform_governance","tags":["AI and human rights"]},{"image":"data/resources/60.jpg","nr":"60","title":"Online Platforms' Moderation of Illegal Content Online Law, Practices and Options for Reform","category":"Read","subtitle":"Policy Department for Economic, Scientific and Quality of Life Policies at the request of the committee on Internal Market and Consumer Protection (IMCO), European Parliament, 2020","description":"A report evaluating how automated content-filtering technologies can restrict the display of unlawful or otherwise problematic content but can also lead to over censorship of online speech, particularly discussions of gender equality and hate speech.","href":"https://op.europa.eu/en/publication-detail/-/publication/cd388309-cc89-11ea-adf7-01aa75ed71a1","tags":["AI in content moderation: Illegal content and security threats"]},{"image":"data/resources/61.jpg","nr":"61","title":"Mixed messages? The limits of automated social media content analysis","category":"Read","subtitle":"Natasha Duarte, Emma Llansó, and Anna Loup, Center for Democracy & Technology, 2017","description":"An in-depth analysis of the limits and potential human rights harms of using artificial intelligence and other types of automation to analyze content on social media. According to the authors, “policymakers must understand these limitations before endorsing or adopting automated content analysis tools. Without proper safeguards, these tools can facilitate overbroad censorship and biased enforcement of laws and of platforms’ terms of service.”","tags":["AI and human rights","AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/62.jpg","nr":"62","title":"Artificial Intelligence, Content Moderation, and Freedom of Expression","category":"Read","subtitle":"Emma Llansó, Joris van Hoboken, Paddy Leerssen, and Jaron Harambam\nWorking paper of the Transatlantic Working Group on Content Moderation Online and Freedom of Expression, 2020","description":"A working paper on the use of AI and automation to moderation and curate online content and the challenges this raises for the rights to freedom of expression and access to information. Part I focuses on content moderation and the use of automated systems for detecting and evaluating content at scale. Part II focuses on content curation and questions about the role of recommendation algorithms in amplifying hate speech, violent extremism, and disinformation.","href":"https://www.ivir.nl/publicaties/download/AI-Llanso-Van-Hoboken-Feb-2020.pdf","tags":["AI and human rights"]},{"image":"data/resources/63.jpg","nr":"63","title":"Everything in Moderation: An Analysis of How Internet Platforms Are Using Artificial Intelligence to Moderate User-Generated Content","category":"Read","subtitle":"Spandana Singh, Open Technology Institute, 2019","description":"A report focusing on the automated content moderation policies and practices of three platforms—Facebook, Reddit, and Tumblr—to highlight the different ways these tools are deployed to police content and the challenges associated with each of them.","href":"https://www.newamerica.org/oti/reports/everything-moderation-analysis-how-internet-platforms-are-using-artificial-intelligence-moderate-user-generated-content","tags":["AI in content moderation: Illegal content and security threats","AI in content moderation: (Legal yet harmful content and) hate speech"]},{"image":"data/resources/64.jpg","nr":"64","title":"Report of the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression on artificial intelligence","category":"Read","subtitle":"submitted in accordance with Human Rights Council resolution 34/18, 2018","description":"A report by then UN Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression, David Kaye that identifies the human rights legal framework relevant to artificial intelligence and presenting preliminary recommendations for ensuring human rights are built into the development and deployment of these technologies.","href":"https://freedex.org/wp-content/blogs.dir/2015/files/2018/10/AI-and-FOE-GA.pdf","tags":["AI and human rights","AI governance"]},{"image":"data/resources/65.jpg","nr":"65","title":"Report of the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression","category":"Read","subtitle":"submitted to the Human Rights Council (A/HRC/38/35), 2018","description":"A human rights-centered approach to online content moderation presented by then UN Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression, David Kaye.","href":"https://undocs.org/A/HRC/38/35","tags":["AI and human rights","AI governance"]},{"image":"data/resources/66.jpg","nr":"66","title":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms","category":"Read","subtitle":"Big Data & Society, 2016","description":"Jenna Burrell, a researcher from the University of California, considers the issue of algorithmic opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring.","href":"https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512","tags":["AI and human rights"]},{"image":"data/resources/67.jpg","nr":"67","title":"Who Should Decide What We See Online?","category":"Read","subtitle":"Jascha Galaski, Civil Liberties for Europe, 2021","description":"A report by Civil Liberties for Europe on how online platforms rank and moderate content, and advocating for regulatory responses that prioritize transparency and the protection of fundamental expression and privacy rights.","href":"https://www.liberties.eu/en/stories/automation-and-illegal-content-article-2/18219","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/68.jpg","nr":"68","title":"AI Regulation: Present Situation And Future Possibilities","category":"Read","subtitle":"Jascha Galaski, Civil Liberties for Europe, 2021","description":"The report by Civil Liberties for Europe addresses how the use of AI systems by public authorities and companies can have a significant impact on our lives—and calls for regulatory solutions that ensure these technologies do not enable manipulation or promote bias.","href":"https://www.liberties.eu/en/stories/ai-regulation/43740","tags":["AI and human rights"]},{"image":"data/resources/69.jpg","nr":"69","title":"The invisible curation of content: Facebook’s News Feed and our information diets","category":"Read","subtitle":"World Wide Web Foundation, 2018","description":"The World Wide Web Foundation explores Facebook’s newsfeed algorithm to show that we have little comprehension of how these systems work, despite the power they have to shape our public discourse.","href":"https://webfoundation.org/research/the-invisiblecuration-of-content-facebooks-news-feed-and-our-information-diets","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/70.jpg","nr":"70","title":"Recommendation CM/Rec(2020)1 of the Committee of Ministers to member States on the human rights impacts of algorithmic systems","category":"Read","subtitle":"Council of Europe, 2020","description":"The Committee of Ministers of the Council of Europe’s recommendations for the public and private sector for safeguarding human rights in their design, development, and deployment of algorithmic systems.","href":"https://search.coe.int/cm/pages/result_details.aspx?objectid=09000016809e1154","tags":["AI and human rights","AI governance"]},{"image":"data/resources/71.jpg","nr":"71","title":"How will artificial intelligence affect international law? Using Human Rights Law to Inform States' Decisions to Deploy AI","category":"Read","subtitle":"Darragh Murray, AJIL Unbound 158, 2020","description":"Both the public and private sectors are investing heavily in the development of new AI tools and technologies. This paper underlines that these technologies are being deployed without a full understanding of their impact on individuals or society, and in the absence of effective domestic or international regulatory frameworks.","href":"http://repository.essex.ac.uk/27479/1/using_human_rights_law_to_inform_states_decisions_to_deploy_ai.pdf","tags":["AI and human rights"]},{"image":"data/resources/72.jpg","nr":"72","title":"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification","category":"Read","subtitle":"Joy Buolamwini and Timnit Gebru, Proceedings of Machine Learning Research, 2018","description":"Machine-learning algorithms can discriminate based on categories such as race and gender. Scholars Joy Buolamwini and Timnit Gebru offer an approach for evaluating bias in automated facial analysis algorithms and datasets.","href":"http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf","tags":["AI and human rights"]},{"image":"data/resources/73.jpg","nr":"73","title":"Privacy and Freedom of Expression in the Age of Artificial Intelligence","category":"Read","subtitle":"Privacy International and Article 19, 2018","description":"A joint paper by Privacy International and Article 19 addressing the privacy and freedom of expression risks of artificial intelligence and machine learning.","href":"https://privacyinternational.org/sites/default/files/2018-04/Privacy%20and%20Freedom%20of%20Expression%20%20In%20the%20Age%20of%20Artificial%20Intelligence.pdf","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/74.jpg","nr":"74","title":"First Things First: Online Advertising Practices and Their Effects on Platform Speech","category":"Read","subtitle":"Jeff Gary and Ashkan Soltani, Knight First Amendment Institute, 2019","description":"Tech policy experts Jeff Gary and Ashkan Soltani discuss the freedom of expression challenges of content moderation. They argue that rather than requiring platforms to remove harmful content, policymakers should instead focus on targeted advertising and the underlying business model that incentivizes and amplifies the proliferation of much of the harmful speech online.","href":"https://knightcolumbia.org/content/first-things-first-online-advertising-practices-and-their-effects-on-platform-speech","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/75.jpg","nr":"75","title":"The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power","category":"Read","subtitle":"Shoshana Zuboff, New York: PublicAffairs, 2019","description":"Harvard professor Shoshana Zuboff examines the growing power of tech companies and suggests that their business models represent a new form of capitalist accumulation that she calls “surveillance capitalism”. This model represents an unprecedented form of corporate power that has flourished free from democratic oversight.","href":"https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/76.jpg","nr":"76","title":"AI, human rights, democracy and the rule of law: A primer prepared for the Council of Europe","category":"Read","subtitle":"The Alan Turing Institute and the Council of Europe, 2021","description":"A primer by The Alan Turing Institute and the Council of Europe summarizing the main concepts presented in the Council of Europe’s Ad Hoc Committee on Artificial Intelligence (CAHAI) Feasibility Studyexploring the impact of AI on human rights and democracy.","href":"https://www.turing.ac.uk/sites/default/files/2021-03/cahai_feasibility_study_primer_final.pdf","tags":["AI and human rights"]},{"image":"data/resources/77.jpg","nr":"77","title":"Algorithms and Human Rights: Study on the Human Rights Dimensions of Automated Data Processing Techniques and Possible Regulatory Implications","category":"Read","subtitle":"Council of Europe study, 2018","description":"An expert report evaluating the impact of algorithms and automated data processing techniques on human rights, including implications for rule of law principles and judiciary processes.","href":"https://edoc.coe.int/en/internet/7589-algorithms-and-human-rights-study-on-the-human-rights-dimensions-of-automated-data-processing-techniques-and-possible-regulatory-implications.html","tags":["AI and human rights"]},{"image":"data/resources/78.jpg","nr":"78","title":"Ad Hoc Committee on Artificial Intelligence (CAHAI)’s Feasibility Study","category":"Read","subtitle":"Council of Europe, 2020","description":"A report exploring the impact of artificial intelligence on human rights and democracy, and providing options for an international legal response that fills existing legislative gaps, and that tailors binding and non-binding legal instruments to the specific risks and opportunities presented by AI systems.","href":"https://rm.coe.int/cahai-2020-23-final-eng-feasibility-study-/1680a0c6da","tags":["AI and human rights"]},{"image":"data/resources/79.jpg","nr":"79","title":"Implications of AI-driven tools in the media for freedom of expression","category":"Read","subtitle":"Council of Europe Background Paper, Ministerial Conference, Cyprus, 28-29, 2020","description":"An expert paper exploring the implications of AI-driven tools on the media and freedom of expression. Authors evaluate how AI systems can limit or narrow the availability of news content and information, which have detrimental effects on the public sphere and on the diversity of media markets.","href":"https://rm.coe.int/cyprus-2020-ai-and-freedom-of-expression/168097fa82","tags":["AI in content curation: Media pluralism"]},{"image":"data/resources/80.jpg","nr":"80","title":"Are Algorithms a Threat to Democracy? The Rise of Intermediaries: A Challenge for Public Discourse","category":"Read","subtitle":"Birgit Stark, Daniel Stegmann, Melanie Magin, and Pascal Jürgens, Algorithm Watch, 2020","description":"Researchers at the Berlin-based NGO Algorithm Watch explore how algorithms threaten public discourse and democracy. This report explores key research on how algorithmic news curation can drive the development of so-called “echo chambers,” and finds that while the effects of such filter bubbles can be overstated the risk of societal fragmentation and polarization remains.","href":"https://algorithmwatch.org/en/wp-content/uploads/2020/05/Governing-Platforms-communications-study-Stark-May-2020-AlgorithmWatch.pdf","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/81.jpg","nr":"81","title":"Tech-Giants, Freedom of Expression and the Right to Privacy","category":"Read","subtitle":"Rikke Frank Jørgensen and Marya Akhtar, The Danish Institute for Human Rights, 2020","description":"A report by researchers at the Danish Institute for Human Rights addressing how content moderation and curation by digital platforms can affect freedom of expression and the right to privacy and protection of personal data.","href":"https://www.humanrights.dk/sites/humanrights.dk/files/media/document/Tech-giants.pdf","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"nr":"82","title":"How Business Models Have Shaped Big Tech","category":"Listen","subtitle":"The World as You'll Know It podcast, Season 02, Episode 03. September 7, 2021","description":"Host of The World As You’ll Know It podcast Kurt Andersen speaks with Roger McNamee, author of Zucked: Waking Up to the Facebook Catastrophe (2019), about the evolution of Facebook and other Big Tech companies and what measures might be taken to curb their influence.","href":"https://megaphone.link/CAD3900484376","tags":["AI in content curation: Surveillance capitalism","AI in content curation: Media pluralism"]},{"image":"data/resources/83.jpg","nr":"83","title":"AI, Free Speech & Human Rights","category":"Listen","subtitle":"Techdirt Podcast Episode 187. October 30, 2018","description":"Artificial intelligence is raising complex questions about free speech, privacy, and other important rights. An in-depth discussion on artificial intelligence and its implications on human rights with David Kaye, former UN Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression.","href":"https://www.techdirt.com/articles/20181030/12502240941/techdirt-podcast-episode-187-ai-free-speech-human-rights.shtml","tags":["AI and human rights"]},{"image":"data/resources/84.jpg","nr":"84","title":"How online misinformation murdered the truth","category":"Read","subtitle":"MIT Tech Review’s DeepTech podcast. October 20, 2020","description":"MIT Tech Review reporters Abby Ohlheiser and Patrick Howell O’Neill discuss how internet platforms failed to control the flood of misinformation ahead of the 2020 U.S. presidential election. “[It’s] as if the platforms were trying to stop a river from flooding by tossing out water in buckets,” according to Ohlheiser.","href":"https://www.technologyreview.com/2020/10/29/1011409/podcast-how-online-misinformation-murdered-the-truth","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/85.jpg","nr":"85","title":"Algorithmic governance and the state of impact assessment in the EU, US, and Canada","category":"Listen","subtitle":"Data & Society podcast. June 23, 2021","description":"Data & Society Program Director Jacob Metcalf hosts a conversation with tech policy experts Sarah Chander, Fenwick McKelvey, Brittany Smith, and Jake Metcalf on the emerging AI regulations in the EU, U.S., and Canada, and asks how human rights impact assessments can help mitigate harms caused by algorithmic systems.","href":"https://datasociety.net/library/algorithmic-governance-and-the-state-of-impact-assessment-in-the-eu-us-and-canada","tags":["AI and human rights"]},{"image":"data/resources/86.jpg","nr":"86","title":"Echo Chambers","category":"Read","subtitle":"A.I. Nation, Ep. 5. April 29, 2021","description":"A.I. Nation, a podcast of Princeton University’s Center for Information Technology Policy and Philadelphia Public Radio station WHYY, examines the role of AI technologies in driving politically polarizing ideas in the U.S., discussing how such tools generate online echo chambers and fuel the virulent spread of disinformation and misinformation on social media.","href":"https://whyy.org/episodes/ep-5-echo-chambers","tags":["AI in content curation: Media pluralism","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/87.jpg","nr":"87","title":"How democracies can reclaim digital power","category":"Listen","subtitle":"MIT Tech Review’s DeepTech podcast. October 15, 2020","description":"In this episode of MIT Tech Review’s Deep Tech podcast, Dutch former MEP Marietje Schaake discusses how national regulators are not doing enough to enforce democratic values in technology. She joins MIT Tech ReviewEditor-in-Chief Gideon Lichfield to discuss how decisions made in the interests of business are dictating the lives of billions of people.","href":"https://www.technologyreview.com/2020/10/15/1010571/podcast-democracies-digital-power","tags":["AI and human rights"]},{"nr":"88","title":"Serving you up on the internet","category":"Listen","subtitle":"Better Human podcast, Episode 50. June 29, 2021","description":"International human rights lawyer Susie Alegre hosts a discussion with Dr. Elif Kuskonmaz, a professor at the University of Portsmouth, about how tech companies have adopted deeply privacy-invasive surveillance and data-harvesting practices that are having profound implications for freedom of expression, access to information, and other human rights.","href":"https://anchor.fm/better-human/episodes/50---Serving-you-up-on-the-internet-e13jrtj","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/89.jpg","nr":"89","title":"Are internet algorithms a problem for human rights?","category":"Listen","subtitle":"Better Human podcast, Episode 49. June 9, 2021","description":"A discussion with university professor Lorna Woods about how AI-driven technologies are shaping the digital content we see and access, and how this affects fundamental freedom of expression and privacy rights.","href":"https://anchor.fm/better-human/episodes/9---Algorithms--mind-control-and-the-right-to-freedom-of-thought-ea0l8o","tags":["AI in content curation: Surveillance capitalism"]},{"image":"data/resources/90.jpg","nr":"90","title":"Are algorithms making us less creative?","category":"Listen","subtitle":"Better Human podcast, Episode 47. April 19, 2021","description":"Do automatically curated news feeds help or hinder free expression? How does creativity interact with rights protections? A discussion with Brendan de Caires of PEN Canada, hosted by barristers Adam Wagner and Susie Alegre, about the impact of AI on writers.","href":"https://anchor.fm/better-human/episodes/47---Are-algorithms-making-us-less-creative-ev5uop/a-a59noki","tags":["AI and human rights","AI in content curation: Media pluralism"]},{"image":"data/resources/91.jpg","nr":"91","title":"Social media disinformation in the age of Covid","category":"Listen","subtitle":"Better Human podcast, Episode 41. January 13, 2021","description":"What is disinformation, how does it spread, and can it be stopped? Meetali Jain, Legal Director at Avaaz, joins host Susie Alegre, international human rights lawyer, to discuss how AI-driven tools power disinformation and other types of harmful digital content, and what can be done about it.","href":"https://getpodcast.com/fr/podcast/better-human-podcast/41-social-media-disinformation-in-the-age-of-covid_ad32279e3c","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/92.jpg","nr":"92","title":"Are we truly free to express our opinions?","category":"Listen","subtitle":"Better Human podcast, Episode 44. March 2, 2021","description":"Evelyn Aswad, a professor at the University of Oklahoma College of Law, discusses freedom of opinion and how it interacts with freedom of speech.","href":"https://www.patreon.com/posts/new-episode-are-48204614","tags":["AI and human rights"]},{"image":"data/resources/93.jpg","nr":"93","title":"Social media, mind control and the right to freedom of thought","category":"Listen","subtitle":"Better Human podcast. Episode 9. January 6, 2020","description":"Are algorithms controlling our thoughts? Is Facebook like a totalitarian state? How can we stop political parties using our innermost thoughts to influence our decision-making? International human rights barrister Susie Alegre and Adam Wagner discuss how the human right to freedom of thought might be the most useful prism through which to answer these questions.","href":"https://anchor.fm/better-human/episodes/9---Algorithms--mind-control-and-the-right-to-freedom-of-thought-ea0l8o/a-a193taf","tags":["AI and human rights"]},{"image":"data/resources/94.jpg","nr":"94","title":"How AI can affect human rights","category":"Read","subtitle":"Essex University’s Human Rights Centre","description":"This video, produced by Essex University’s Human Rights Centre, presents the human rights challenges posed by surveillance capitalism and the mass collection and processing of personal data.","href":"https://www.essex.ac.uk/research-projects/human-rights-big-data-and-technology","tags":["AI and human rights"]},{"image":"data/resources/95.jpg","nr":"95","title":"Algorithmic Accountability: A Primer","category":"Read","subtitle":"Data & Society, 2018","description":"A primer that unpacks key AI concepts and definitions, including how AI can reinforce bias and discrimination.","href":"https://datasociety.net/wp-content/uploads/2018/04/Data_Society_Algorithmic_Accountability_Primer_FINAL-4.pdf","tags":["AI and human rights"]},{"image":"data/resources/96.jpg","nr":"96","title":"AI for dummies","category":"Read","subtitle":"Civil Liberties for Europe, 2021","description":"This primer for non-tech audiences breaks down the fundamentals of AI and provides simple responses to questions such as: What is artificial intelligence? Why is it artificial?","href":"https://www.liberties.eu/en/stories/artificial-intelligence-for-dummies/43527","tags":["AI and human rights"]},{"image":"data/resources/97.jpg","nr":"97","title":"AI Observatory","category":"Read","description":"A project by individuals and communities in India affected by artificial intelligence and automated decision-making systems, which evaluates and breaks down how these technologies are used by government institutions in India.","href":"https://ai-observatory.in","tags":["AI and human rights"]},{"image":"data/resources/98.jpg","nr":"98","title":"Defending Human Rights in the Age of Artificial Intelligence","category":"Read","subtitle":"UNESCO and United Nations Institute for Training and Research (UNITAR)","description":"A nine-unit interactive course for youth on AI and Human Rights developed jointly by UNESCO and United Nations Institute for Training and Research (UNITAR). This course breaks down complex concepts on how freedom of expression, the right to privacy, and the right to equality are affected using AI.","href":"https://www.edapp.com/course/defending-human-rights-in-the-age-of-artificial-intelligence-2","tags":["AI and human rights"]},{"image":"data/resources/99.jpg","nr":"99","title":"The Anatomy of an AI system","category":"Read","subtitle":"Vladan Joler and Kate Crawford, 2018","description":"An anatomical map and long-form essay of human labor, data, and planetary resources required to power Amazon Echo, created by scholars Vladan Joler, a professor at the Art Academy of the University of Novi Sad and co-founder of the SHARE Foundation, and Kate Crawford, a professor at New York University and co-founder and co-director of the AI Now Institute.","href":"https://anatomyof.ai","tags":["AI and human rights","AI in content curation: Surveillance capitalism"]},{"image":"data/resources/100.jpg","nr":"100","title":"The Toronto Declaration","category":"Read","subtitle":"May 2018","description":"Led by Amnesty International and Access Now, the Toronto Declaration calls on governments and companies to urgently protect human rights in the age of artificial intelligence, with a focus on the right to equality and non-discrimination.","href":"https://www.torontodeclaration.org","tags":["AI and human rights","AI governance"]},{"image":"data/resources/101.jpg","nr":"101","title":"The Santa Clara Principles 2.9","category":"Read","subtitle":"December 2021","description":"A set of minimum transparency and accountability standards for the moderation of online content, developed in 2018 and updated in 2021 by a consortium of civil society organizations and academics.","href":"https://santaclaraprinciples.org","tags":["AI and human rights","AI governance"]},{"image":"data/resources/102.jpg","nr":"102","title":"The Manila Principles","category":"Read","subtitle":"May 2015","description":"Developed by the Electronic Frontier Foundation and other NGOs, the Manila Principles are a set of standards related to online censorship and content takedowns to help governments develop laws and processes that protect freedom of expression.","href":"https://manilaprinciples.org/index.html","tags":["AI and human rights","AI governance"]},{"nr":"103","title":"Practical guidance for businesses, and other actors in the digital ecosystem, on how to conduct human rights impact assessment of digital activities","category":"Read","subtitle":"Danish Institute for Human Rights, 2020","description":"The Danish Institute for Human Rights’ guidance for conducting human rights impact assessments for private and public sector entities that design, develop, sell, procure, deploy, apply or otherwise use digital projects, products and services.","href":"https://www.humanrights.dk/publications/human-rights-impact-assessment-digital-activities","tags":["AI and human rights"]},{"image":"data/resources/104.jpg","nr":"104","title":"UNESCO Guidelines for the Governance of Digital Platforms","category":"Read","subtitle":"UNESCO, November 2023\n","description":"UNESCO developed Guidelines that aim to safeguarding freedom of expression and access to information online in the context of the development and implementation of digital platform regulatory processes.","href":"https://www.unesco.org/en/internet-conference/guidelines","tags":["AI and human rights","AI governance"]}]